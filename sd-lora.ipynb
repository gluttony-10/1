{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f06bea55-7889-4576-a83b-d3b207729e3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Stable Diffusion WebUI 带lora训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fab4ab6-be4b-4206-ba12-8dad73bac833",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 阿里云 DSW 一键脚本 By bilibili@十字鱼\n",
    "### 基于bilibili@秋葉aaaki大佬的云端包修改并整合\n",
    "\n",
    "#### 简介\n",
    "\n",
    "- 十字鱼 https://space.bilibili.com/893892\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39df08ff-45e4-4a86-add4-a5af9cc7f7d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1 安装 第一次运行时执行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ceb62d-9c19-4bce-a060-7fdaecf95ca0",
   "metadata": {},
   "source": [
    "### 1.1 SD安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567fe4a3-a897-48b6-bde2-0afb3d064c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /mnt/workspace\n",
    "!git clone https://gitcode.net/overbill1683/stable-diffusion-webui\n",
    "%cd stable-diffusion-webui\n",
    "!mkdir repositories\n",
    "%cd repositories\n",
    "!git clone \"https://gitcode.net/overbill1683/stablediffusion\" \"stable-diffusion-stability-ai\"\n",
    "!git clone \"https://gitcode.net/overbill1683/taming-transformers\" \"taming-transformers\"\n",
    "!git clone \"https://gitcode.net/overbill1683/k-diffusion\" \"k-diffusion\"\n",
    "!git clone \"https://gitcode.net/overbill1683/CodeFormer\" \"CodeFormer\"\n",
    "!git clone \"https://gitcode.net/overbill1683/BLIP\" \"BLIP\"\n",
    "%cd /mnt/workspace/stable-diffusion-webui\n",
    "!wget -O \"config.json\" \"https://gitcode.net/Akegarasu/sd-webui-configs/-/raw/master/config.json\"\n",
    "# 安装常用插件\n",
    "extensions = [\n",
    "    \"https://gitcode.net/ranting8323/a1111-sd-webui-tagcomplete\",\n",
    "    \"https://gitcode.net/ranting8323/stable-diffusion-webui-localization-zh_CN\",\n",
    "    \"https://gitcode.net/ranting8323/sd-webui-additional-networks\",\n",
    "]\n",
    "%cd /mnt/workspace/stable-diffusion-webui\n",
    "for e in extensions:\n",
    "    !git -C \"extensions\" clone {e}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84e17ce-ed04-4e65-926b-1049b03dbd29",
   "metadata": {},
   "source": [
    "### 1.2 lora训练安装\n",
    "- 不训练可跳过\n",
    "- ./lora-scripts/sd-scripts文件夹里有文件才成功"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29c0c31d-ea47-4056-9ace-ff044cc42cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://mirrors.cloud.aliyuncs.com/ubuntu jammy InRelease\n",
      "Hit:2 http://mirrors.cloud.aliyuncs.com/ubuntu jammy-updates InRelease\n",
      "Hit:3 http://mirrors.cloud.aliyuncs.com/ubuntu jammy-backports InRelease\n",
      "Hit:4 http://mirrors.cloud.aliyuncs.com/ubuntu jammy-security InRelease\n",
      "Reading package lists... Done3m\u001b[33m\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "28 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "aria2 is already the newest version (1.36.0-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 28 not upgraded.\n",
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m/mnt/workspace\n",
      "fatal: destination path 'lora-scripts' already exists and is not an empty directory.\n",
      "/mnt/workspace/lora-scripts\n",
      "mkdir: cannot create directory ‘train’: File exists\n",
      "/mnt/workspace/lora-scripts/train\n",
      "mkdir: cannot create directory ‘10_glut’: File exists\n",
      "/mnt/workspace/lora-scripts\n",
      "HEAD is now at 6d1ad41 update\n",
      "Already up to date.\n",
      "--2023-04-27 19:14:22--  https://ghproxy.com/https://github.com/gluttony-10/lora-scripts/blob/main/train.sh\n",
      "Resolving ghproxy.com (ghproxy.com)... 144.22.239.90\n",
      "Connecting to ghproxy.com (ghproxy.com)|144.22.239.90|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 FOUND\n",
      "Location: https://fastly.jsdelivr.net/gh/gluttony-10/lora-scripts@main/train.sh [following]\n",
      "--2023-04-27 19:14:23--  https://fastly.jsdelivr.net/gh/gluttony-10/lora-scripts@main/train.sh\n",
      "Resolving fastly.jsdelivr.net (fastly.jsdelivr.net)... 151.101.109.229, 2a04:4e42:1a::485\n",
      "Connecting to fastly.jsdelivr.net (fastly.jsdelivr.net)|151.101.109.229|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7342 (7.2K) [application/x-sh]\n",
      "Saving to: ‘train.sh’\n",
      "\n",
      "train.sh            100%[===================>]   7.17K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-04-27 19:14:25 (152 MB/s) - ‘train.sh’ saved [7342/7342]\n",
      "\n",
      "Looking in indexes: https://mirrors.bfsu.edu.cn/pypi/web/simple\n",
      "Looking in links: https://mirror.sjtu.edu.cn/pytorch-wheels/torch_stable.html\n",
      "Requirement already satisfied: torch==2.0.0+cu118 in /usr/local/lib/python3.10/dist-packages (2.0.0+cu118)\n",
      "Requirement already satisfied: torchvision==0.15.1+cu118 in /usr/local/lib/python3.10/dist-packages (0.15.1+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0+cu118) (3.10.7)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0+cu118) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0+cu118) (1.12rc1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0+cu118) (3.1rc0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0+cu118) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0+cu118) (2.0.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1+cu118) (1.23.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1+cu118) (2.28.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1+cu118) (9.4.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0+cu118) (3.26.1)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0+cu118) (16.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0+cu118) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1+cu118) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1+cu118) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1+cu118) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1+cu118) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0+cu118) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.bfsu.edu.cn/pypi/web/simple\n",
      "Collecting xformers==0.0.17\n",
      "  Using cached https://mirrors.bfsu.edu.cn/pypi/web/packages/db/4b/9a0d2549367896f0de260977c144c6ff7b5079356e31e414d5bce6e4bdd5/xformers-0.0.17-cp310-cp310-manylinux2014_x86_64.whl (123.6 MB)\n",
      "Installing collected packages: xformers\n",
      "Successfully installed xformers-0.0.16rc425\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m/mnt/workspace/lora-scripts/sd-scripts\n",
      "Looking in indexes: https://mirrors.bfsu.edu.cn/pypi/web/simple\n",
      "Processing /mnt/workspace/lora-scripts/sd-scripts\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: accelerate==0.15.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.15.0)\n",
      "Requirement already satisfied: transformers==4.26.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (4.26.0)\n",
      "Requirement already satisfied: ftfy==6.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (6.1.1)\n",
      "Requirement already satisfied: albumentations==1.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: opencv-python==4.7.0.68 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.7.0.68)\n",
      "Requirement already satisfied: einops==0.6.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.6.0)\n",
      "Requirement already satisfied: diffusers[torch]==0.10.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.10.2)\n",
      "Requirement already satisfied: pytorch-lightning==1.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (1.9.0)\n",
      "Requirement already satisfied: bitsandbytes==0.35.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (0.35.0)\n",
      "Requirement already satisfied: tensorboard==2.10.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (2.10.1)\n",
      "Requirement already satisfied: safetensors==0.2.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (0.2.6)\n",
      "Requirement already satisfied: gradio==3.16.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (3.16.2)\n",
      "Requirement already satisfied: altair==4.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (4.2.2)\n",
      "Requirement already satisfied: easygui==0.98.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.98.3)\n",
      "Requirement already satisfied: toml==0.10.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (0.10.2)\n",
      "Requirement already satisfied: voluptuous==0.13.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.13.1)\n",
      "Requirement already satisfied: requests==2.28.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (2.28.2)\n",
      "Requirement already satisfied: timm==0.6.12 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (0.6.12)\n",
      "Requirement already satisfied: fairscale==0.4.13 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (0.4.13)\n",
      "Requirement already satisfied: tensorflow==2.10.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 23)) (2.10.1)\n",
      "Requirement already satisfied: huggingface-hub==0.13.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 24)) (0.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.15.0->-r requirements.txt (line 1)) (1.23.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.15.0->-r requirements.txt (line 1)) (23.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.15.0->-r requirements.txt (line 1)) (5.9.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.15.0->-r requirements.txt (line 1)) (6.0)\n",
      "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.15.0->-r requirements.txt (line 1)) (2.0.0+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.0->-r requirements.txt (line 2)) (3.10.7)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.0->-r requirements.txt (line 2)) (2023.3.23)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.0->-r requirements.txt (line 2)) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.0->-r requirements.txt (line 2)) (4.65.0)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy==6.1.1->-r requirements.txt (line 3)) (0.2.6)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.0->-r requirements.txt (line 4)) (1.10.1)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.0->-r requirements.txt (line 4)) (0.19.2)\n",
      "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.0->-r requirements.txt (line 4)) (0.0.4)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.0->-r requirements.txt (line 4)) (4.7.0.72)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers[torch]==0.10.2->-r requirements.txt (line 7)) (6.1.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers[torch]==0.10.2->-r requirements.txt (line 7)) (9.4.0)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (2023.3.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (0.11.4)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (4.5.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (0.8.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.10.1->-r requirements.txt (line 10)) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.10.1->-r requirements.txt (line 10)) (1.53.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.10.1->-r requirements.txt (line 10)) (2.17.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.10.1->-r requirements.txt (line 10)) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.10.1->-r requirements.txt (line 10)) (3.4.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.10.1->-r requirements.txt (line 10)) (3.19.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard==2.10.1->-r requirements.txt (line 10)) (59.6.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.10.1->-r requirements.txt (line 10)) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.10.1->-r requirements.txt (line 10)) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.10.1->-r requirements.txt (line 10)) (2.2.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard==2.10.1->-r requirements.txt (line 10)) (0.37.1)\n",
      "Requirement already satisfied: aiofiles in /usr/local/lib/python3.10/dist-packages (from gradio==3.16.2->-r requirements.txt (line 12)) (23.1.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from gradio==3.16.2->-r requirements.txt (line 12)) (3.8.4)\n",
      "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio==3.16.2->-r requirements.txt (line 12)) (0.95.1)\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio==3.16.2->-r requirements.txt (line 12)) (0.3.0)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio==3.16.2->-r requirements.txt (line 12)) (0.23.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio==3.16.2->-r requirements.txt (line 12)) (3.1.2)\n",
      "Requirement already satisfied: markdown-it-py[linkify,plugins] in /usr/local/lib/python3.10/dist-packages (from gradio==3.16.2->-r requirements.txt (line 12)) (2.2.0)\n",
      "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio==3.16.2->-r requirements.txt (line 12)) (2.1.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio==3.16.2->-r requirements.txt (line 12)) (3.7.1)\n",
      "Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from gradio==3.16.2->-r requirements.txt (line 12)) (3.8.9)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gradio==3.16.2->-r requirements.txt (line 12)) (1.5.3)\n",
      "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.10/dist-packages (from gradio==3.16.2->-r requirements.txt (line 12)) (3.17)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio==3.16.2->-r requirements.txt (line 12)) (1.10.7)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio==3.16.2->-r requirements.txt (line 12)) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio==3.16.2->-r requirements.txt (line 12)) (0.0.6)\n",
      "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (from gradio==3.16.2->-r requirements.txt (line 12)) (0.21.1)\n",
      "Requirement already satisfied: websockets>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.16.2->-r requirements.txt (line 12)) (11.0)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.txt (line 13)) (0.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.txt (line 13)) (4.17.3)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.txt (line 13)) (0.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.28.2->-r requirements.txt (line 18)) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.28.2->-r requirements.txt (line 18)) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.28.2->-r requirements.txt (line 18)) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.28.2->-r requirements.txt (line 18)) (2022.12.7)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm==0.6.12->-r requirements.txt (line 19)) (0.15.1+cu118)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (23.3.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (3.8.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (16.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (3.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (0.32.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (2.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (1.15.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.16.2->-r requirements.txt (line 12)) (22.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.16.2->-r requirements.txt (line 12)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.16.2->-r requirements.txt (line 12)) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.16.2->-r requirements.txt (line 12)) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.16.2->-r requirements.txt (line 12)) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.16.2->-r requirements.txt (line 12)) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.10.1->-r requirements.txt (line 10)) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.10.1->-r requirements.txt (line 10)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.10.1->-r requirements.txt (line 10)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.10.1->-r requirements.txt (line 10)) (1.3.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair==4.2.2->-r requirements.txt (line 13)) (0.19.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio==3.16.2->-r requirements.txt (line 12)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio==3.16.2->-r requirements.txt (line 12)) (2023.3)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations==1.3.0->-r requirements.txt (line 4)) (1.2.2)\n",
      "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0->-r requirements.txt (line 4)) (3.1rc0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0->-r requirements.txt (line 4)) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0->-r requirements.txt (line 4)) (2023.3.21)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0->-r requirements.txt (line 4)) (1.4.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate==0.15.0->-r requirements.txt (line 1)) (1.12rc1)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate==0.15.0->-r requirements.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate==0.15.0->-r requirements.txt (line 1)) (3.26.1)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate==0.15.0->-r requirements.txt (line 1)) (16.0.0)\n",
      "Requirement already satisfied: starlette<0.27.0,>=0.26.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio==3.16.2->-r requirements.txt (line 12)) (0.26.1)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.16.2->-r requirements.txt (line 12)) (0.15.0)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.16.2->-r requirements.txt (line 12)) (1.5.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.16.2->-r requirements.txt (line 12)) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers[torch]==0.10.2->-r requirements.txt (line 7)) (3.15.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]->gradio==3.16.2->-r requirements.txt (line 12)) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]->gradio==3.16.2->-r requirements.txt (line 12)) (2.0.0)\n",
      "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]->gradio==3.16.2->-r requirements.txt (line 12)) (0.3.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.16.2->-r requirements.txt (line 12)) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.16.2->-r requirements.txt (line 12)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.16.2->-r requirements.txt (line 12)) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.16.2->-r requirements.txt (line 12)) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.16.2->-r requirements.txt (line 12)) (3.0.9)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->gradio==3.16.2->-r requirements.txt (line 12)) (8.1.3)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn->gradio==3.16.2->-r requirements.txt (line 12)) (0.12.0)\n",
      "Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx->gradio==3.16.2->-r requirements.txt (line 12)) (3.6.2)\n",
      "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]->gradio==3.16.2->-r requirements.txt (line 12)) (1.0.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.10.1->-r requirements.txt (line 10)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.10.1->-r requirements.txt (line 10)) (3.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.0->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.0->-r requirements.txt (line 4)) (3.1.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->accelerate==0.15.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Building wheels for collected packages: library\n",
      "  Building wheel for library (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for library: filename=library-0.0.0-py3-none-any.whl size=73003 sha256=e4ee84d4fe7540302f4875606aaea93ebceb7b062ec94db229e769d870f90d6b\n",
      "  Stored in directory: /root/.cache/pip/wheels/6e/cf/a5/47c9639b82e5337cc20568a5423d115519ad46ef0199d07522\n",
      "Successfully built library\n",
      "Installing collected packages: library\n",
      "  Attempting uninstall: library\n",
      "    Found existing installation: library 0.0.0\n",
      "    Uninstalling library-0.0.0:\n",
      "      Successfully uninstalled library-0.0.0\n",
      "Successfully installed library-0.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.bfsu.edu.cn/pypi/web/simple\n",
      "Requirement already satisfied: lion-pytorch in /usr/local/lib/python3.10/dist-packages (0.0.7)\n",
      "Requirement already satisfied: dadaptation in /usr/local/lib/python3.10/dist-packages (2.0)\n",
      "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from lion-pytorch) (2.0.0+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->lion-pytorch) (3.10.7)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->lion-pytorch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->lion-pytorch) (1.12rc1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->lion-pytorch) (3.1rc0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->lion-pytorch) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->lion-pytorch) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->lion-pytorch) (3.26.1)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->lion-pytorch) (16.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->lion-pytorch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->lion-pytorch) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.bfsu.edu.cn/pypi/web/simple\n",
      "Requirement already satisfied: lycoris-lora in /usr/local/lib/python3.10/dist-packages (0.1.5)\n",
      "Requirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (from lycoris-lora) (0.10.2)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from lycoris-lora) (0.2.6)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from lycoris-lora) (2.0.0+cu118)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from lycoris-lora) (4.26.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers->lycoris-lora) (6.1.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers->lycoris-lora) (3.10.7)\n",
      "Requirement already satisfied: huggingface-hub>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from diffusers->lycoris-lora) (0.13.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers->lycoris-lora) (1.23.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers->lycoris-lora) (2023.3.23)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers->lycoris-lora) (2.28.2)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers->lycoris-lora) (9.4.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->lycoris-lora) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->lycoris-lora) (1.12rc1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->lycoris-lora) (3.1rc0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->lycoris-lora) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->lycoris-lora) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->lycoris-lora) (3.26.1)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->lycoris-lora) (16.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->lycoris-lora) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->lycoris-lora) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->lycoris-lora) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->lycoris-lora) (4.65.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers->lycoris-lora) (3.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->lycoris-lora) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers->lycoris-lora) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers->lycoris-lora) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers->lycoris-lora) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers->lycoris-lora) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->lycoris-lora) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.bfsu.edu.cn/pypi/web/simple\n",
      "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (0.95.1)\n",
      "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (0.21.1)\n",
      "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from fastapi) (1.10.7)\n",
      "Requirement already satisfied: starlette<0.27.0,>=0.26.1 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.26.1)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.3)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.12.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2->fastapi) (4.5.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.27.0,>=0.26.1->fastapi) (3.6.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.27.0,>=0.26.1->fastapi) (2.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.27.0,>=0.26.1->fastapi) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "nvidia-cuda-toolkit is already the newest version (11.5.1-1ubuntu1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 28 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "!apt update\n",
    "!apt install -y aria2\n",
    "!python -m pip install --upgrade pip\n",
    "%cd /mnt/workspace\n",
    "!git clone --recurse-submodules https://ghproxy.com/https://github.com/Akegarasu/lora-scripts\n",
    "if os.path.exists('lora-scripts'):\n",
    "    %cd lora-scripts\n",
    "    !mkdir train\n",
    "    %cd train\n",
    "    !mkdir 10_glut\n",
    "    %cd ../\n",
    "    !git reset --hard\n",
    "    !git pull\n",
    "    !git submodule init\n",
    "    !git submodule update\n",
    "    !wget -O \"train.sh\" \"https://ghproxy.com/https://github.com/gluttony-10/lora-scripts/blob/main/train.sh\"\n",
    "    !pip install torch==2.0.0+cu118 torchvision==0.15.1+cu118 -f https://mirror.sjtu.edu.cn/pytorch-wheels/torch_stable.html -i https://mirrors.bfsu.edu.cn/pypi/web/simple\n",
    "    !pip install -U -I --no-deps xformers==0.0.17 -i https://mirrors.bfsu.edu.cn/pypi/web/simple\n",
    "    if os.path.exists('sd-scripts'):\n",
    "        %cd sd-scripts\n",
    "        !pip install --upgrade -r requirements.txt -i https://mirrors.bfsu.edu.cn/pypi/web/simple\n",
    "        !pip install --upgrade lion-pytorch dadaptation -i https://mirrors.bfsu.edu.cn/pypi/web/simple\n",
    "        !pip install --upgrade lycoris-lora -i https://mirrors.bfsu.edu.cn/pypi/web/simple\n",
    "        !pip install --upgrade fastapi uvicorn -i https://mirrors.bfsu.edu.cn/pypi/web/simple\n",
    "        !sudo apt-get install -y nvidia-cuda-toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced6371a-1cff-4dbf-9400-459ebb588df2",
   "metadata": {},
   "source": [
    "## 2 下载模型和VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c290ca4-0880-41e1-b1c5-58fd9a755bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aria2(url, filename, d):\n",
    "    !aria2c --console-log-level=error -c -x 16 -s 16 {url} -o {filename} -d {d}\n",
    "\n",
    "model_url = \"https://huggingface.co/swl-models/chilloutmix/resolve/main/Chilloutmix.safetensors\"\n",
    "aria2(model_url, model_url.split(\"/\")[-1], \"/mnt/workspace/stable-diffusion-webui/models/Stable-diffusion\")\n",
    "\n",
    "VAE_URL = \"https://huggingface.co/Yukihime256/840000/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\"\n",
    "aria2(VAE_URL, VAE_URL.split(\"/\")[-1], \"/mnt/workspace/stable-diffusion-webui/models/VAE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383abdf0",
   "metadata": {},
   "source": [
    "## 3 下载其他文件（可跳过）\n",
    "- 这部分是可选的，有需要再执行！修改对应文本，运行即可下载文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1dd7015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Download Progress Summary as of Thu Apr 27 19:19:14 2023 ***              3m28s\u001b[0m\u001b[35m]\u001b[0m\u001b[0mm\n",
      "===============================================================================\n",
      "[#956803 1.7GiB/1.9GiB(88%) CN:9 DL:1.0MiB ETA:3m43s]\n",
      "FILE: /mnt/workspace/stable-diffusion-webui/models/Stable-diffusion/anything-v4.5-pruned-fp16.ckpt\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Thu Apr 27 19:20:15 2023 ***              4m35s\u001b[0m\u001b[35m]\u001b[0m\u001b[0m\n",
      "===============================================================================\n",
      "[#956803 1.8GiB/1.9GiB(91%) CN:8 DL:634KiB ETA:4m36s]\n",
      "FILE: /mnt/workspace/stable-diffusion-webui/models/Stable-diffusion/anything-v4.5-pruned-fp16.ckpt\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Thu Apr 27 19:21:15 2023 ***              3m9s\u001b[0m\u001b[35m]\u001b[0m\u001b[0mm\n",
      "===============================================================================\n",
      "[#956803 1.8GiB/1.9GiB(93%) CN:8 DL:704KiB ETA:3m7s]\n",
      "FILE: /mnt/workspace/stable-diffusion-webui/models/Stable-diffusion/anything-v4.5-pruned-fp16.ckpt\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Thu Apr 27 19:22:16 2023 ***              1m41s\u001b[0m\u001b[35m]\u001b[0m\u001b[0m\n",
      "===============================================================================\n",
      "[#956803 1.9GiB/1.9GiB(96%) CN:8 DL:749KiB ETA:1m45s]\n",
      "FILE: /mnt/workspace/stable-diffusion-webui/models/Stable-diffusion/anything-v4.5-pruned-fp16.ckpt\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[35m[\u001b[0m#956803 1.9GiB/1.9GiB\u001b[36m(99%)\u001b[0m CN:1 DL:\u001b[32m5.0MiB\u001b[0m\u001b[35m]\u001b[0m\u001b[0m0m\u001b[35m]\u001b[0m\u001b[0mmmm\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "956803|\u001b[1;32mOK\u001b[0m  |   7.2MiB/s|/mnt/workspace/stable-diffusion-webui/models/Stable-diffusion/anything-v4.5-pruned-fp16.ckpt\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n"
     ]
    }
   ],
   "source": [
    "DOWNLOAD_URL = \"https://huggingface.co/andite/anything-v4.0/resolve/main/anything-v4.5-pruned-fp16.ckpt\"\n",
    "SAVE_DIR = \"/mnt/workspace/stable-diffusion-webui/models/Stable-diffusion\"\n",
    "aria2(DOWNLOAD_URL, DOWNLOAD_URL.split(\"/\")[-1], SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b67fda1-6a9a-44c4-879f-70fbf114d175",
   "metadata": {},
   "source": [
    "## 4 训练lora（可跳过）\n",
    "- 训练文件放进./lora-scripts/train/10_glut中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "498bbaab-fd8a-47bc-a218-69b103753f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/workspace/lora-scripts\n",
      "prepare tokenizer\n",
      "Downloading (…)olve/main/vocab.json: 100%|███| 961k/961k [00:00<00:00, 4.08MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|███| 525k/525k [00:00<00:00, 1.20MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████| 389/389 [00:00<00:00, 827kB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|█████| 905/905 [00:00<00:00, 1.96MB/s]\n",
      "update token length: 225\n",
      "Use DreamBooth method.\n",
      "prepare images.\n",
      "found directory train/10_glut contains 30 image files\n",
      "300 train images with repeating.\n",
      "0 reg images.\n",
      "no regularization images / 正則化画像が見つかりませんでした\n",
      "[Dataset 0]\n",
      "  batch_size: 3\n",
      "  resolution: (512, 512)\n",
      "  enable_bucket: True\n",
      "  min_bucket_reso: 256\n",
      "  max_bucket_reso: 1024\n",
      "  bucket_reso_steps: 64\n",
      "  bucket_no_upscale: False\n",
      "\n",
      "  [Subset 0 of Dataset 0]\n",
      "    image_dir: \"train/10_glut\"\n",
      "    image_count: 30\n",
      "    num_repeats: 10\n",
      "    shuffle_caption: True\n",
      "    keep_tokens: 0\n",
      "    caption_dropout_rate: 0.0\n",
      "    caption_dropout_every_n_epoches: 0\n",
      "    caption_tag_dropout_rate: 0.0\n",
      "    color_aug: False\n",
      "    flip_aug: False\n",
      "    face_crop_aug_range: None\n",
      "    random_crop: False\n",
      "    token_warmup_min: 1,\n",
      "    token_warmup_step: 0,\n",
      "    is_reg: False\n",
      "    class_tokens: glut\n",
      "    caption_extension: .txt\n",
      "\n",
      "\n",
      "[Dataset 0]\n",
      "loading image sizes.\n",
      "100%|█████████████████████████████████████████| 30/30 [00:00<00:00, 3010.05it/s]\n",
      "make buckets\n",
      "number of images (including repeats) / 各bucketの画像枚数（繰り返し回数を含む）\n",
      "bucket 0: resolution (512, 512), count: 300\n",
      "mean ar error (without repeats): 0.0\n",
      "prepare accelerator\n",
      "Using accelerator 0.15.0 or above.\n",
      "loading model for process 0/1\n",
      "load StableDiffusion checkpoint\n",
      "/usr/local/lib/python3.10/dist-packages/safetensors/torch.py:98: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(filename, framework=\"pt\", device=device) as f:\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/usr/local/lib/python3.10/dist-packages/torch/storage.py:899: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = cls(wrap_storage=untyped_storage)\n",
      "loading u-net: <All keys matched successfully>\n",
      "loading vae: <All keys matched successfully>\n",
      "Downloading (…)lve/main/config.json: 100%|█| 4.52k/4.52k [00:00<00:00, 7.61MB/s]\n",
      "Downloading pytorch_model.bin: 100%|███████| 1.71G/1.71G [26:10<00:00, 1.09MB/s]\n",
      "loading text encoder: <All keys matched successfully>\n",
      "Replace CrossAttention.forward to use xformers\n",
      "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "[Dataset 0]\n",
      "caching latents.\n",
      "100%|███████████████████████████████████████████| 30/30 [00:04<00:00,  6.80it/s]\n",
      "import network module: networks.lora\n",
      "create LoRA network. base dim (rank): 32, alpha: 32.0\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "prepare optimizer, data loader etc.\n",
      "use Lion optimizer | {}\n",
      "override steps. steps for 10 epochs is / 指定エポックまでのステップ数: 1000\n",
      "running training / 学習開始\n",
      "  num train images * repeats / 学習画像の数×繰り返し回数: 300\n",
      "  num reg images / 正則化画像の数: 0\n",
      "  num batches per epoch / 1epochのバッチ数: 100\n",
      "  num epochs / epoch数: 10\n",
      "  batch size per device / バッチサイズ: 3\n",
      "  gradient accumulation steps / 勾配を合計するステップ数 = 1\n",
      "  total optimization steps / 学習ステップ数: 1000\n",
      "steps:   0%|                                           | 0/1000 [00:00<?, ?it/s]epoch 1/10\n",
      "/usr/local/lib/python3.10/dist-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()\n",
      "steps:  10%|██▏                   | 100/1000 [00:35<05:20,  2.81it/s, loss=0.14]saving checkpoint: ./output/glut-000001.safetensors\n",
      "epoch 2/10\n",
      "steps:  20%|████▏                | 200/1000 [01:10<04:43,  2.82it/s, loss=0.137]saving checkpoint: ./output/glut-000002.safetensors\n",
      "epoch 3/10\n",
      "steps:  30%|██████▌               | 300/1000 [01:46<04:07,  2.82it/s, loss=0.14]saving checkpoint: ./output/glut-000003.safetensors\n",
      "epoch 4/10\n",
      "steps:  40%|████████▍            | 400/1000 [02:21<03:32,  2.82it/s, loss=0.142]saving checkpoint: ./output/glut-000004.safetensors\n",
      "epoch 5/10\n",
      "steps:  50%|██████████▌          | 500/1000 [02:57<02:57,  2.81it/s, loss=0.126]saving checkpoint: ./output/glut-000005.safetensors\n",
      "epoch 6/10\n",
      "steps:  60%|████████████▌        | 600/1000 [03:33<02:22,  2.81it/s, loss=0.115]saving checkpoint: ./output/glut-000006.safetensors\n",
      "epoch 7/10\n",
      "steps:  70%|██████████████▋      | 700/1000 [04:09<01:47,  2.80it/s, loss=0.113]saving checkpoint: ./output/glut-000007.safetensors\n",
      "epoch 8/10\n",
      "steps:  80%|████████████████▊    | 800/1000 [04:45<01:11,  2.80it/s, loss=0.123]saving checkpoint: ./output/glut-000008.safetensors\n",
      "epoch 9/10\n",
      "steps:  90%|██████████████████▉  | 900/1000 [05:21<00:35,  2.80it/s, loss=0.115]saving checkpoint: ./output/glut-000009.safetensors\n",
      "epoch 10/10\n",
      "steps: 100%|████████████████████| 1000/1000 [05:57<00:00,  2.80it/s, loss=0.128]saving checkpoint: ./output/glut.safetensors\n",
      "model saved.\n",
      "steps: 100%|████████████████████| 1000/1000 [05:57<00:00,  2.79it/s, loss=0.128]\n"
     ]
    }
   ],
   "source": [
    "%cd /mnt/workspace/lora-scripts\n",
    "!bash train.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bff16e-1f2d-4324-b1b8-78758b107eed",
   "metadata": {},
   "source": [
    "## 5 启动WebUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb12c51-eacb-4086-857e-e2eac64ac94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/workspace/stable-diffusion-webui\n",
      "Python 3.10.6 (main, Mar 10 2023, 10:55:28) [GCC 11.3.0]\n",
      "Commit hash: 22bcc7be428c94e9408f589966c2040187245d81\n",
      "Fetching updates for Taming Transformers...\n",
      "Checking out commit for Taming Transformers with hash: 24268930bf1dce879235a7fddd0b2355b84d7ea6...\n",
      "Fetching updates for K-diffusion...\n",
      "Checking out commit for K-diffusion with hash: 5b3af030dd83e0297272d861c19477735d0317ec...\n",
      "Fetching updates for CodeFormer...\n",
      "Checking out commit for CodeFormer with hash: c5b4593074ba6214284d6acd5f1719b6c5d739af...\n",
      "Fetching updates for BLIP...\n",
      "Checking out commit for BLIP with hash: 48211a1594f1321b00f14c9f7a5b4813144b2fb9...\n",
      "Installing requirements for Web UI\n",
      "Launching Web UI with arguments: --no-download-sd-model --xformers --share --listen\n",
      "2023-04-27 19:56:10.036040: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-27 19:56:10.169465: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-27 19:56:10.198587: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-27 19:56:10.703393: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-04-27 19:56:10.703443: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-04-27 19:56:10.703449: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n",
      "[AddNet] Updating model hashes...\n",
      "0it [00:00, ?it/s]\n",
      "[AddNet] Updating model hashes...\n",
      "0it [00:00, ?it/s]\n",
      "Checkpoint Counterfeit-V2.5_fp16.safetensors [71e703a0fc] not found; loading fallback anything-v4.5-pruned-fp16.ckpt\n",
      "Calculating sha256 for /mnt/workspace/stable-diffusion-webui/models/Stable-diffusion/anything-v4.5-pruned-fp16.ckpt: f773383dbc00da6d5ee2779e8242cc3e03aca22bd1520d67eed26f95b62a343f\n",
      "Loading weights [f773383dbc] from /mnt/workspace/stable-diffusion-webui/models/Stable-diffusion/anything-v4.5-pruned-fp16.ckpt\n",
      "Creating model from config: /mnt/workspace/stable-diffusion-webui/configs/v1-inference.yaml\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 859.52 M params.\n",
      "Loading VAE weights specified in settings: /mnt/workspace/stable-diffusion-webui/models/VAE/animevae.pt\n",
      "Applying xformers cross attention optimization.\n",
      "Textual inversion embeddings loaded(0): \n",
      "Model loaded in 8.0s (calculate hash: 2.0s, load weights from disk: 1.0s, create model: 0.4s, apply weights to model: 0.6s, apply half(): 0.3s, load VAE: 3.3s, move model to device: 0.3s).\n",
      "Running on local URL:  http://0.0.0.0:7860\n",
      "Running on public URL: https://de8bead1ffdee8b5a1.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n",
      "Startup time: 17.0s (import torch: 2.6s, import gradio: 0.7s, import ldm: 0.8s, other imports: 0.9s, setup codeformer: 0.1s, load scripts: 0.6s, load SD checkpoint: 8.0s, create ui: 0.2s, gradio launch: 3.0s).\n",
      "Calculating sha256 for /mnt/workspace/stable-diffusion-webui/models/Stable-diffusion/Chilloutmix.safetensors: a757fe8b3dc64e12fa7aacd14f816e18a80ffab003b05c147d40ef6c6ecb1861\n",
      "Loading weights [a757fe8b3d] from /mnt/workspace/stable-diffusion-webui/models/Stable-diffusion/Chilloutmix.safetensors\n",
      "Loading VAE weights specified in settings: /mnt/workspace/stable-diffusion-webui/models/VAE/animevae.pt\n",
      "Applying xformers cross attention optimization.\n",
      "Weights loaded in 8.4s (calculate hash: 7.0s, load weights from disk: 0.5s, apply weights to model: 0.2s, load VAE: 0.5s, move model to device: 0.3s).\n",
      "[AddNet] Updating model hashes...\n",
      "100%|██████████████████████████████████████████| 10/10 [00:00<00:00, 898.81it/s]\n",
      "[AddNet] Updating model hashes...\n",
      "100%|████████████████████████████████████████| 10/10 [00:00<00:00, 25435.44it/s]\n",
      "X/Y/Z plot will create 50 images on 1 10x5 grid. (Total steps to process: 1000)\n",
      "\n",
      "Total progress: 0it [00:00, ?it/s]\u001b[ALoRA weight_unet: 0.6, weight_tenc: 0.6, model: glut-000001(d10c7295ae95)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.6, multiplier_tenc: 0.6\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000001(d10c7295ae95) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:02<00:52,  2.76s/it]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:02<00:22,  1.24s/it]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:03<00:12,  1.33it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:03<00:08,  1.91it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:03<00:05,  2.51it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:03<00:04,  3.10it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:03<00:03,  3.65it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:03<00:02,  4.14it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:04<00:02,  4.54it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:04<00:02,  4.84it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:04<00:01,  5.09it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:04<00:01,  5.27it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:04<00:01,  5.42it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:05<00:01,  5.52it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:05<00:00,  5.61it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:05<00:00,  5.67it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:05<00:00,  5.67it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:05<00:00,  5.73it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:05<00:00,  5.78it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.35it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.6, weight_tenc: 0.6, model: glut-000002(371a100b93f4)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.6, multiplier_tenc: 0.6\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000002(371a100b93f4) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.57it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.67it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.71it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.74it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.75it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.73it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.75it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.78it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.79it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.81it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.79it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.80it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.79it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.80it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.82it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.81it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:02<00:00,  5.81it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.84it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.87it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.95it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.6, weight_tenc: 0.6, model: glut-000003(62139a0e85a4)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.6, multiplier_tenc: 0.6\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000003(62139a0e85a4) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.96it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.86it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.83it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.83it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.82it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.78it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.79it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.79it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.78it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.79it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.78it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.79it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.80it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.81it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.82it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.80it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:02<00:00,  5.80it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.82it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.85it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.97it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.6, weight_tenc: 0.6, model: glut-000004(261c246cdb81)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.6, multiplier_tenc: 0.6\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000004(261c246cdb81) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.98it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.85it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.83it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.82it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.77it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.76it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.76it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.77it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.77it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.78it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.77it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.72it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.73it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.75it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.76it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.78it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:02<00:00,  5.79it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.80it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.84it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.94it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.6, weight_tenc: 0.6, model: glut-000005(7bba42b2be41)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.6, multiplier_tenc: 0.6\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000005(7bba42b2be41) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.88it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.81it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.80it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.78it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.76it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.73it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.76it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.75it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.77it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.77it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.75it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.75it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.77it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.72it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.73it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.76it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:02<00:00,  5.75it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.77it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.80it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.92it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.6, weight_tenc: 0.6, model: glut-000006(d80ebbf6a9d6)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.6, multiplier_tenc: 0.6\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000006(d80ebbf6a9d6) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.90it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.69it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.73it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.73it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.75it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.72it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.73it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.74it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.76it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.75it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.74it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.75it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.76it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.76it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.77it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.75it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:02<00:00,  5.75it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.78it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.81it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.91it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.6, weight_tenc: 0.6, model: glut-000007(a17f014a414f)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.6, multiplier_tenc: 0.6\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000007(a17f014a414f) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.68it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.72it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.75it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.73it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.73it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.70it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.73it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.74it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.75it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.76it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.74it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.73it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.75it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.77it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.76it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.72it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:02<00:00,  5.73it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.76it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.79it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.90it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.6, weight_tenc: 0.6, model: glut-000008(cd134040c9fc)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.6, multiplier_tenc: 0.6\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000008(cd134040c9fc) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.92it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.81it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.79it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.76it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.73it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.69it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.71it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.71it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.73it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.73it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.72it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.71it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.70it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.73it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.74it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.74it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:02<00:00,  5.73it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.76it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.78it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.89it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.6, weight_tenc: 0.6, model: glut-000009(bf2df7ce73a9)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.6, multiplier_tenc: 0.6\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000009(bf2df7ce73a9) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.89it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.79it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.78it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.74it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.73it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.68it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.67it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.69it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.70it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.68it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.69it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.71it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.68it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.69it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.71it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.72it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:02<00:00,  5.72it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.75it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.79it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.88it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.6, weight_tenc: 0.6, model: glut(04cea84fb92a)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.6, multiplier_tenc: 0.6\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut(04cea84fb92a) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.94it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.78it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.74it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.73it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.71it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.69it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.71it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.73it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.73it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.72it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.71it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.72it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.72it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.73it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.73it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.72it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:02<00:00,  5.70it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.73it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.76it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.88it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.7, weight_tenc: 0.7, model: glut-000001(d10c7295ae95)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.7, multiplier_tenc: 0.7\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000001(d10c7295ae95) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.94it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.79it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.77it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.75it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.74it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.69it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.70it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.71it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.72it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.72it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.69it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.70it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.70it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.71it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.71it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.71it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:02<00:00,  5.70it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.73it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.75it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.88it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.7, weight_tenc: 0.7, model: glut-000002(371a100b93f4)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.7, multiplier_tenc: 0.7\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000002(371a100b93f4) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.84it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.78it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.75it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.73it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.71it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.68it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.68it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.70it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.70it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.70it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.70it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.71it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.69it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.70it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.71it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.72it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:02<00:00,  5.71it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.74it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.78it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.87it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.7, weight_tenc: 0.7, model: glut-000003(62139a0e85a4)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.7, multiplier_tenc: 0.7\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000003(62139a0e85a4) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.87it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.76it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.74it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.71it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.70it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.68it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.70it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.70it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.68it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.66it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.58it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.62it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.65it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.68it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.70it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.71it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:02<00:00,  5.73it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.76it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.78it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.86it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.7, weight_tenc: 0.7, model: glut-000004(261c246cdb81)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.7, multiplier_tenc: 0.7\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000004(261c246cdb81) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.91it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.79it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.78it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.76it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.70it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.68it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.70it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.72it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.73it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.72it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.71it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.71it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.71it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.72it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.73it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.74it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:02<00:00,  5.73it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.75it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.78it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.89it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.7, weight_tenc: 0.7, model: glut-000005(7bba42b2be41)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.7, multiplier_tenc: 0.7\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000005(7bba42b2be41) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.85it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.78it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.75it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.73it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.72it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.68it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.69it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.70it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.71it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.71it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.71it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.72it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.72it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.70it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.71it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.72it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:02<00:00,  5.73it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.76it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.78it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.88it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.7, weight_tenc: 0.7, model: glut-000006(d80ebbf6a9d6)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.7, multiplier_tenc: 0.7\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000006(d80ebbf6a9d6) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.87it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.77it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.75it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.70it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.71it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.68it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.69it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.70it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.70it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.70it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.70it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.70it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.71it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.72it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.73it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.64it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:02<00:00,  5.67it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.71it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.75it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.86it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.7, weight_tenc: 0.7, model: glut-000007(a17f014a414f)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.7, multiplier_tenc: 0.7\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000007(a17f014a414f) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.84it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.78it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.75it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.74it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.74it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.69it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.69it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.71it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.72it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.73it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.70it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.70it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.70it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.72it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.73it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.72it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:02<00:00,  5.72it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.75it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.77it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.88it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.7, weight_tenc: 0.7, model: glut-000008(cd134040c9fc)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.7, multiplier_tenc: 0.7\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000008(cd134040c9fc) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.84it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.77it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.74it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.72it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.71it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.68it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.69it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.70it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.71it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.71it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.65it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.67it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.68it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.70it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.68it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.70it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:02<00:00,  5.71it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.72it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.75it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.86it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.7, weight_tenc: 0.7, model: glut-000009(bf2df7ce73a9)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.7, multiplier_tenc: 0.7\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000009(bf2df7ce73a9) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.89it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.77it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.74it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.71it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.71it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.66it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.68it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.63it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.65it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.66it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.64it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.66it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.68it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.70it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.70it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.69it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:02<00:00,  5.70it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.72it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.74it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.85it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.7, weight_tenc: 0.7, model: glut(04cea84fb92a)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.7, multiplier_tenc: 0.7\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut(04cea84fb92a) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.88it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.75it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.73it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.73it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.70it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.65it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.67it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.68it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.69it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.69it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.68it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.66it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.68it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.70it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.70it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.70it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:02<00:00,  5.70it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.73it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.70it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.85it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.8, weight_tenc: 0.8, model: glut-000001(d10c7295ae95)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.8, multiplier_tenc: 0.8\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000001(d10c7295ae95) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.88it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.79it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.75it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.72it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.71it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.68it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.69it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.71it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.70it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.69it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.68it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.69it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.68it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.69it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.67it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.69it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:02<00:00,  5.69it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.70it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.73it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.86it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.8, weight_tenc: 0.8, model: glut-000002(371a100b93f4)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.8, multiplier_tenc: 0.8\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000002(371a100b93f4) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.86it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.76it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.75it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.67it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.67it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.65it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.67it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.68it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.68it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.69it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.68it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.69it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.70it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.71it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.70it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.70it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:02<00:00,  5.68it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.72it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.75it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.86it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.8, weight_tenc: 0.8, model: glut-000003(62139a0e85a4)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.8, multiplier_tenc: 0.8\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000003(62139a0e85a4) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.88it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.78it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.74it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.72it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.70it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.66it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.68it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.69it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.70it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.70it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.69it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.69it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.65it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.68it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.68it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.69it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:02<00:00,  5.70it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.72it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.74it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.86it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.8, weight_tenc: 0.8, model: glut-000004(261c246cdb81)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.8, multiplier_tenc: 0.8\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000004(261c246cdb81) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.62it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.64it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:03,  5.66it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.66it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.65it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.67it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.68it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.69it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.69it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.69it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.69it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.69it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.70it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.71it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.68it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.70it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:02<00:00,  5.70it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.74it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.77it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.85it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.8, weight_tenc: 0.8, model: glut-000005(7bba42b2be41)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.8, multiplier_tenc: 0.8\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000005(7bba42b2be41) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.90it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.78it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.75it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.73it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.68it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.66it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.66it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.67it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.68it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.68it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.65it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.66it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.67it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.68it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.70it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.70it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:02<00:00,  5.69it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.72it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.75it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.85it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.8, weight_tenc: 0.8, model: glut-000006(d80ebbf6a9d6)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.8, multiplier_tenc: 0.8\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000006(d80ebbf6a9d6) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.87it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.74it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.72it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.69it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.67it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.64it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.67it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.67it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.68it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.69it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.67it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.68it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.66it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.67it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.64it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.64it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:02<00:00,  5.65it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.69it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.71it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.83it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.8, weight_tenc: 0.8, model: glut-000007(a17f014a414f)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.8, multiplier_tenc: 0.8\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000007(a17f014a414f) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.88it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.75it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.71it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.69it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.68it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.65it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.66it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.68it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.67it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.68it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.67it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.68it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.69it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.69it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.68it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.68it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:02<00:00,  5.69it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.71it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.75it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.85it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.8, weight_tenc: 0.8, model: glut-000008(cd134040c9fc)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.8, multiplier_tenc: 0.8\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000008(cd134040c9fc) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.90it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.78it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.75it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.72it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.59it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.59it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.61it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.64it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.66it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.65it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.65it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.66it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.68it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.68it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.68it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.68it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:03<00:00,  5.65it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.69it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.72it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.83it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.8, weight_tenc: 0.8, model: glut-000009(bf2df7ce73a9)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.8, multiplier_tenc: 0.8\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000009(bf2df7ce73a9) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.87it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.75it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.73it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.66it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.63it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.62it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.64it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.65it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.67it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.66it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.64it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.65it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.65it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.66it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.68it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.66it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:03<00:00,  5.66it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.70it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.72it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.83it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.8, weight_tenc: 0.8, model: glut(04cea84fb92a)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.8, multiplier_tenc: 0.8\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut(04cea84fb92a) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.75it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.72it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.71it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.68it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.66it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.64it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.65it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.67it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.68it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.67it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.65it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.66it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.66it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.64it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.66it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.66it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:03<00:00,  5.66it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.69it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.72it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.83it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.9, weight_tenc: 0.9, model: glut-000001(d10c7295ae95)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.9, multiplier_tenc: 0.9\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000001(d10c7295ae95) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.78it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.69it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.68it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.64it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.63it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.62it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.64it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.63it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.59it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.59it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.61it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.64it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.63it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.65it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.65it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.66it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:03<00:00,  5.64it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.67it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.69it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.80it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.9, weight_tenc: 0.9, model: glut-000002(371a100b93f4)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.9, multiplier_tenc: 0.9\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000002(371a100b93f4) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.84it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.75it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.72it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.70it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.66it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.63it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.64it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.65it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.65it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.65it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.65it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.63it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.64it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.66it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.67it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.66it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:03<00:00,  5.66it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.68it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.71it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.82it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.9, weight_tenc: 0.9, model: glut-000003(62139a0e85a4)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.9, multiplier_tenc: 0.9\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000003(62139a0e85a4) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.87it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.71it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.70it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.68it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.65it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.62it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.63it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.63it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.65it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.65it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.65it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.64it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.63it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.61it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.64it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.65it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:03<00:00,  5.66it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.67it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.68it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.81it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.9, weight_tenc: 0.9, model: glut-000004(261c246cdb81)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.9, multiplier_tenc: 0.9\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000004(261c246cdb81) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.86it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.74it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.72it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.69it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.67it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.65it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.64it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.65it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.65it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.64it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.63it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.64it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.65it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.66it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.66it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.65it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:03<00:00,  5.63it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.67it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.71it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.82it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.9, weight_tenc: 0.9, model: glut-000005(7bba42b2be41)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.9, multiplier_tenc: 0.9\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000005(7bba42b2be41) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.85it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.74it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.70it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.68it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.65it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.63it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.65it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.65it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.66it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.66it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.63it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.55it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.58it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.61it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.64it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.65it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:03<00:00,  5.64it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.67it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.70it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.81it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.9, weight_tenc: 0.9, model: glut-000006(d80ebbf6a9d6)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.9, multiplier_tenc: 0.9\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000006(d80ebbf6a9d6) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.71it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.67it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:03,  5.66it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.65it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.64it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.63it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.64it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.65it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.65it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.63it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.63it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.65it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.65it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.66it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.67it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.67it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:03<00:00,  5.66it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.69it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.72it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.81it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.9, weight_tenc: 0.9, model: glut-000007(a17f014a414f)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.9, multiplier_tenc: 0.9\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000007(a17f014a414f) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.80it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.71it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.68it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.66it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.64it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.62it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.63it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.65it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.65it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.64it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.63it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.63it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.63it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.64it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.62it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.64it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:03<00:00,  5.62it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.66it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.68it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.80it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.9, weight_tenc: 0.9, model: glut-000008(cd134040c9fc)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.9, multiplier_tenc: 0.9\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000008(cd134040c9fc) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.83it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.71it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.69it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.68it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.65it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.61it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.62it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.64it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.65it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.65it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.61it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.64it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.65it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.65it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.66it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.66it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:03<00:00,  5.64it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.66it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.70it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.81it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.9, weight_tenc: 0.9, model: glut-000009(bf2df7ce73a9)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.9, multiplier_tenc: 0.9\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000009(bf2df7ce73a9) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.86it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.74it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.70it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.68it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.65it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.63it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.65it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.65it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.66it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.64it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.63it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.63it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.61it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.64it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.65it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.64it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:03<00:00,  5.65it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.67it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.71it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.81it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 0.9, weight_tenc: 0.9, model: glut(04cea84fb92a)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 0.9, multiplier_tenc: 0.9\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut(04cea84fb92a) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.82it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.72it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.69it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.64it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.63it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.62it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.64it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.65it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.65it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.64it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.60it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.62it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.63it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.65it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.65it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.64it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:03<00:00,  5.63it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.64it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.67it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.80it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 1.0, weight_tenc: 1.0, model: glut-000001(d10c7295ae95)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 1.0, multiplier_tenc: 1.0\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000001(d10c7295ae95) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.84it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.71it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.68it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.66it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.62it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.59it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.61it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.63it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.63it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.63it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.61it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.60it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.61it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.63it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.65it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.64it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:03<00:00,  5.64it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.67it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.69it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.80it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 1.0, weight_tenc: 1.0, model: glut-000002(371a100b93f4)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 1.0, multiplier_tenc: 1.0\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000002(371a100b93f4) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.77it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.71it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.68it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.65it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.62it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.61it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.63it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.64it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.65it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.64it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.63it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.65it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.64it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.64it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.66it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.65it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:03<00:00,  5.65it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.65it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.62it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.79it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 1.0, weight_tenc: 1.0, model: glut-000003(62139a0e85a4)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 1.0, multiplier_tenc: 1.0\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000003(62139a0e85a4) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.85it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.71it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.68it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.65it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.62it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.61it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.62it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.63it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.64it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.64it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.62it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.63it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.63it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.64it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.62it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.65it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:03<00:00,  5.59it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.64it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.67it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.79it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 1.0, weight_tenc: 1.0, model: glut-000004(261c246cdb81)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 1.0, multiplier_tenc: 1.0\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000004(261c246cdb81) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.82it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.70it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.67it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.64it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.63it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.63it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.62it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.64it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.64it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.63it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.63it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.63it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.63it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.65it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.65it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.66it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:03<00:00,  5.65it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.67it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.70it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.81it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 1.0, weight_tenc: 1.0, model: glut-000005(7bba42b2be41)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 1.0, multiplier_tenc: 1.0\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000005(7bba42b2be41) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.82it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.71it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.70it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.66it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.63it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.60it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.62it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.64it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.64it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.63it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.63it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.63it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.61it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.62it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.64it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.65it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:03<00:00,  5.64it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.65it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.69it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.80it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 1.0, weight_tenc: 1.0, model: glut-000006(d80ebbf6a9d6)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 1.0, multiplier_tenc: 1.0\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000006(d80ebbf6a9d6) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.85it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.74it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.71it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.66it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.64it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.62it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.63it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.64it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.65it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.65it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.63it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.63it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.65it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.63it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.65it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.64it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:03<00:00,  5.63it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.66it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.70it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.81it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 1.0, weight_tenc: 1.0, model: glut-000007(a17f014a414f)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 1.0, multiplier_tenc: 1.0\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000007(a17f014a414f) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.82it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.70it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.67it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.64it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.62it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.61it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.62it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.63it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.63it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.63it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.63it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.63it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.64it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.64it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.64it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.62it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:03<00:00,  5.64it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.66it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.69it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.80it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 1.0, weight_tenc: 1.0, model: glut-000008(cd134040c9fc)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 1.0, multiplier_tenc: 1.0\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000008(cd134040c9fc) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.80it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.70it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.69it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.66it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.64it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.62it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.62it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.63it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.63it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.63it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.62it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.62it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.63it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.64it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.65it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.64it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:03<00:00,  5.64it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.67it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.71it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.80it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 1.0, weight_tenc: 1.0, model: glut-000009(bf2df7ce73a9)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 1.0, multiplier_tenc: 1.0\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut-000009(bf2df7ce73a9) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.79it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.70it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.68it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.66it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.63it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.62it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.62it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.63it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.64it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.64it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.63it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.63it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.65it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.65it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.65it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.66it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:03<00:00,  5.65it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.67it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.70it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.81it/s]\u001b[A\n",
      "restoring last networks\n",
      "original forward/weights is restored.\n",
      "LoRA weight_unet: 1.0, weight_tenc: 1.0, model: glut(04cea84fb92a)\n",
      "dimension: {32}, alpha: {32.0}, multiplier_unet: 1.0, multiplier_tenc: 1.0\n",
      "create LoRA for Text Encoder: 72 modules.\n",
      "create LoRA for U-Net: 192 modules.\n",
      "original forward/weights is backed up.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "shapes for 0 weights are converted.\n",
      "LoRA model glut(04cea84fb92a) loaded: <All keys matched successfully>\n",
      "setting (or sd model) changed. new networks created.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  5%|██▏                                         | 1/20 [00:00<00:03,  5.85it/s]\u001b[A\n",
      " 10%|████▍                                       | 2/20 [00:00<00:03,  5.74it/s]\u001b[A\n",
      " 15%|██████▌                                     | 3/20 [00:00<00:02,  5.67it/s]\u001b[A\n",
      " 20%|████████▊                                   | 4/20 [00:00<00:02,  5.61it/s]\u001b[A\n",
      " 25%|███████████                                 | 5/20 [00:00<00:02,  5.60it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 6/20 [00:01<00:02,  5.60it/s]\u001b[A\n",
      " 35%|███████████████▍                            | 7/20 [00:01<00:02,  5.62it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 8/20 [00:01<00:02,  5.64it/s]\u001b[A\n",
      " 45%|███████████████████▊                        | 9/20 [00:01<00:01,  5.64it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 10/20 [00:01<00:01,  5.63it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 11/20 [00:01<00:01,  5.62it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:02<00:01,  5.61it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 13/20 [00:02<00:01,  5.64it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 14/20 [00:02<00:01,  5.66it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:02<00:00,  5.66it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:02<00:00,  5.66it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:03<00:00,  5.65it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:03<00:00,  5.68it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:03<00:00,  5.71it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.81it/s]\u001b[A\n",
      "\n",
      "Total progress: 100%|███████████████████████| 1000/1000 [03:32<00:00,  4.71it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "package_envs  = [\n",
    "      {\n",
    "        \"env\": \"GFPGAN_PACKAGE\",\n",
    "        \"url\": \"git+https://gitcode.net/overbill1683/GFPGAN.git@8d2447a2d918f8eba5a4a01463fd48e45126a379\"\n",
    "      },\n",
    "      {\n",
    "        \"env\": \"CLIP_PACKAGE\",\n",
    "        \"url\": \"git+https://gitcode.net/overbill1683/CLIP.git@d50d76daa670286dd6cacf3bcd80b5e4823fc8e1\"\n",
    "      },\n",
    "      {\n",
    "        \"env\": \"OPENCLIP_PACKAGE\",\n",
    "        \"url\": \"git+https://gitcode.net/overbill1683/open_clip.git@bb6e834e9c70d9c27d0dc3ecedeebeaeb1ffad6b\"\n",
    "      }\n",
    "]\n",
    "os.environ[\"PIP_INDEX_URL\"] = \"https://mirrors.bfsu.edu.cn/pypi/web/simple\"\n",
    "for i in package_envs:\n",
    "    os.environ[i[\"env\"]] = i[\"url\"]\n",
    "\n",
    "%cd /mnt/workspace/stable-diffusion-webui\n",
    "!python launch.py --no-download-sd-model --xformers --share --listen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b778a001-6f15-459f-ab52-f0ae75c8c8af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
