{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUfHcxHmT5Oa"
      },
      "source": [
        "# ChatGLM云端包\n",
        "##简介\n",
        "\n",
        "- Colab选择chatglm-6b-int4模型。（无论是GPU还是CPU模式。）\n",
        "\n",
        "- 阿里云选择chatglm-6b模型。（大模型速度快，int模型运行目前会报错。）\n",
        "\n",
        "- 阿里云的显存支持训练，运行3.4.后再运行2.。Colab勉强也能训练，但是无法检验效果。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPxlJ5VUT5Oc"
      },
      "outputs": [],
      "source": [
        "#@title 0.查看显卡\n",
        "#@markdown 查看显卡信息。（可跳过）\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPxlJ5VUT5Oc"
      },
      "outputs": [],
      "source": [
        "#@title 1.安装依赖\n",
        "#@markdown 失败时请重试。（git库有时候链接不上很正常）\n",
        "#@markdown 下载模型时间较长且没有提示，请耐心等待。\n",
        "import os\n",
        "!pip install --upgrade pip\n",
        "#Colab路径\n",
        "%cd /content\n",
        "#阿里云路径\n",
        "%cd /mnt/workspace\n",
        "!git clone https://ghproxy.com/https://github.com/gluttony-10/ChatGLM-Lora.git\n",
        "if os.path.exists('ChatGLM-Lora'):\n",
        " %cd ChatGLM-Lora\n",
        " !git pull\n",
        " !pip install -r requirements.txt\n",
        " #@markdown 选择模型\n",
        " #@markdown 阿里云选择chatglm-6b（默认），Colab选择chatglm-6b-int4\n",
        " MODEL = \"chatglm-6b\" #@param [\"chatglm-6b\",\"chatglm-6b-int8\",\"chatglm-6b-int4\"]\n",
        " if MODEL == \"chatglm-6b\" :\n",
        "  !git clone --progress -v https://huggingface.co/THUDM/chatglm-6b\n",
        " elif MODEL == \"chatglm-6b-int8\" :\n",
        "  !git clone --progress -v https://huggingface.co/THUDM/chatglm-6b-int8\n",
        " elif MODEL == \"chatglm-6b-int4\" :\n",
        "  !git clone --progress -v https://huggingface.co/THUDM/chatglm-6b-int4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIiyXoP0T5Oj"
      },
      "outputs": [],
      "source": [
        "#@title 2.运行GLM\n",
        "#@markdown 运行成功后，点击gradio网址打开GLM\n",
        "if MODEL == \"chatglm-6b\" :\n",
        " !python webui.py --path chatglm-6b\n",
        "elif MODEL == \"chatglm-6b-int8\" :\n",
        " !python webui.py --path chatglm-6b-int8\n",
        "elif MODEL == \"chatglm-6b-int4\" :\n",
        " !python webui.py --path chatglm-6b-int4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ji-9a7miT5Og"
      },
      "outputs": [],
      "source": [
        "#@title 3.数据转换\n",
        "#@markdown 9train.json是训练文本，可替换，注意格式\n",
        "!python cover_alpaca2jsonl.py \\\n",
        "    --data_path 9train.json \\\n",
        "    --save_path 9train.jsonl\n",
        "!python tokenize_dataset_rows.py \\\n",
        "    --jsonl_path 9train.jsonl \\\n",
        "    --save_path data/alpaca \\\n",
        "    --max_seq_length 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_sWa2EyT5Oh"
      },
      "outputs": [],
      "source": [
        "#@title 4.训练\n",
        "#@markdown 参数可修改\n",
        "#@markdown Colab训练模型要选chatglm-6b，并且要把--lora_rank 32改为--lora_rank 8\n",
        "!wandb off #阿里云用\n",
        "!python finetune.py \\\n",
        "    --dataset_path data/alpaca \\\n",
        "    --lora_rank 32 \\\n",
        "    --per_device_train_batch_size 6 \\\n",
        "    --gradient_accumulation_steps 1 \\\n",
        "    --max_steps 1000 \\\n",
        "    --save_steps 1000 \\\n",
        "    --save_total_limit 2 \\\n",
        "    --learning_rate 1e-4 \\\n",
        "    --fp16 \\\n",
        "    --remove_unused_columns false \\\n",
        "    --logging_steps 50 \\\n",
        "    --output_dir output"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "25273a2a68c96ebac13d7fb9e0db516f9be0772777a0507fe06d682a441a3ba7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}